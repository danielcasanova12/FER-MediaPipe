{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn\n",
    "# %pip install matplotlib\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install seaborn\n",
    "# %pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de imagem e dataset\n",
    "image_size = 100\n",
    "bs = 32  # Tamanho do batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience=5, nameModel='model.pt'):\n",
    "        self.model = model\n",
    "        self.data_loader_treino = data_loader_treino\n",
    "        self.data_loader_validacao = data_loader_validacao\n",
    "        self.num_imagens_treino = num_imagens_treino\n",
    "        self.num_imagens_validacao = num_imagens_validacao\n",
    "        self.device = device\n",
    "        self.funcao_erro = nn.CrossEntropyLoss()\n",
    "        self.otimizador = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "        self.scheduler = ReduceLROnPlateau(self.otimizador, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "        self.patience = patience\n",
    "        self.nameModel = nameModel\n",
    "\n",
    "    def treinar_e_validar(self, epocas):\n",
    "        historico = []\n",
    "        melhor_acuracia = 0.0\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        for epoca in range(epocas):\n",
    "            inicio_epoca = time.time()\n",
    "            print(f\"\\n\\nÉpoca: {epoca + 1}/{epocas}\")\n",
    "            erro_treino, acuracia_treino = self.executar_fase('treino')\n",
    "            erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao = self.executar_fase('validacao', return_predictions=True)\n",
    "\n",
    "            fim_epoca = time.time()\n",
    "            print(f\"Época {epoca + 1}/{epocas}, Treino: Erro: {erro_treino:.4f}, Acurácia: {acuracia_treino * 100:.2f}%, \"\n",
    "                  f\"Validação: Erro: {erro_validacao:.4f}, Acurácia: {acuracia_validacao * 100:.2f}%, Tempo: {fim_epoca - inicio_epoca:.2f}s\")\n",
    "\n",
    "            historico.append([erro_treino, erro_validacao, acuracia_treino, acuracia_validacao])\n",
    "            self.scheduler.step(erro_validacao)\n",
    "\n",
    "            # Early stopping\n",
    "            if acuracia_validacao > melhor_acuracia:\n",
    "                melhor_acuracia = acuracia_validacao\n",
    "                torch.save(self.model.state_dict(), self.nameModel)\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "            if early_stop_counter >= self.patience:\n",
    "                print(\"Parando o treinamento devido ao early stopping.\")\n",
    "                break\n",
    "\n",
    "        # Calcular métricas finais\n",
    "        self.calcular_metricas(predicoes_validacao, labels_validacao)\n",
    "        return historico\n",
    "\n",
    "    def executar_fase(self, fase, return_predictions=False):\n",
    "        if fase == 'treino':\n",
    "            self.model.train()\n",
    "            data_loader = self.data_loader_treino\n",
    "            num_imagens = self.num_imagens_treino\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            data_loader = self.data_loader_validacao\n",
    "            num_imagens = self.num_imagens_validacao\n",
    "\n",
    "        erro_total = 0.0\n",
    "        acuracia_total = 0.0\n",
    "        todas_predicoes = []\n",
    "        todas_labels = []\n",
    "\n",
    "        with torch.set_grad_enabled(fase == 'treino'):\n",
    "            for entradas, labels in data_loader:\n",
    "                entradas, labels = entradas.to(self.device), labels.to(self.device)\n",
    "\n",
    "                if fase == 'treino':\n",
    "                    self.otimizador.zero_grad()\n",
    "\n",
    "                saidas = self.model(entradas)\n",
    "                erro = self.funcao_erro(saidas, labels)\n",
    "\n",
    "                if fase == 'treino':\n",
    "                    erro.backward()\n",
    "                    self.otimizador.step()\n",
    "\n",
    "                erro_total += erro.item() * entradas.size(0)\n",
    "                _, predicoes = torch.max(saidas, 1)\n",
    "                acuracia_total += (predicoes == labels).sum().item()\n",
    "\n",
    "                if return_predictions:\n",
    "                    todas_predicoes.extend(predicoes.cpu().numpy())\n",
    "                    todas_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        erro_medio = erro_total / num_imagens\n",
    "        acuracia_media = acuracia_total / num_imagens\n",
    "\n",
    "        if return_predictions:\n",
    "            return erro_medio, acuracia_media, todas_predicoes, todas_labels\n",
    "        else:\n",
    "            return erro_medio, acuracia_media\n",
    "\n",
    "    def calcular_metricas(self, predicoes, labels):\n",
    "        acuracia = accuracy_score(labels, predicoes)\n",
    "        precisao = precision_score(labels, predicoes, average='weighted')\n",
    "        recall = recall_score(labels, predicoes, average='weighted')\n",
    "        f1 = f1_score(labels, predicoes, average='weighted')\n",
    "\n",
    "        print(\"\\nMétricas de Validação:\")\n",
    "        print(f\"Acurácia: {acuracia:.4f}\")\n",
    "        print(f\"Precisão: {precisao:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "        print(\"\\nRelatório de Classificação:\")\n",
    "        print(classification_report(labels, predicoes))\n",
    "\n",
    "        self.plotar_matriz_confusao(labels, predicoes)\n",
    "\n",
    "    def plotar_matriz_confusao(self, labels, predicoes):\n",
    "        matriz_confusao = confusion_matrix(labels, predicoes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=self.data_loader_treino.dataset.classes, yticklabels=self.data_loader_treino.dataset.classes)\n",
    "        plt.ylabel('Classe Verdadeira')\n",
    "        plt.xlabel('Classe Prevista')\n",
    "        plt.title('Matriz de Confusão')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderSetup:\n",
    "    def __init__(self, dataset_path, image_size=224, batch_size=32):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_transforms(self):\n",
    "        transformacoes_de_imagens = {\n",
    "            'treino': transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomResizedCrop(self.image_size, scale=(0.8, 1.0)),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                transforms.RandomAffine(degrees=20, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'validacao': transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.CenterCrop(self.image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        }\n",
    "        return transformacoes_de_imagens\n",
    "\n",
    "    def load_data(self):\n",
    "        transformacoes = self.get_transforms()\n",
    "        pasta_treino = os.path.join(self.dataset_path, 'treino')\n",
    "        pasta_validacao = os.path.join(self.dataset_path, 'validacao')\n",
    "\n",
    "        data = {\n",
    "            'treino': datasets.ImageFolder(root=pasta_treino, transform=transformacoes['treino']),\n",
    "            'validacao': datasets.ImageFolder(root=pasta_validacao, transform=transformacoes['validacao'])\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    def get_data_loaders(self):\n",
    "        data = self.load_data()\n",
    "        data_loader_treino = DataLoader(data['treino'], batch_size=self.batch_size, shuffle=True)\n",
    "        data_loader_validacao = DataLoader(data['validacao'], batch_size=self.batch_size, shuffle=True)\n",
    "        return data_loader_treino, data_loader_validacao, len(data['treino']), len(data['validacao']), len(data['treino'].classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da classe do modelo Custom ResNet50\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=None):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        for param in list(self.resnet50.parameters())[-4:]:\n",
    "            param.requires_grad = True\n",
    "        self.num_features = self.resnet50.fc.in_features\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        if num_classes is not None:\n",
    "            self.set_num_classes(num_classes)\n",
    "    \n",
    "    def set_num_classes(self, num_classes):\n",
    "        \"\"\"Define o número de classes dinamicamente e substitui a camada fc\"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Linear(self.num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar o modelo\n",
    "def avaliar_modelo(modelo, data_loader, device):\n",
    "    modelo.to(device)\n",
    "    modelo.eval()  # Colocar o modelo em modo de avaliação\n",
    "    todas_predicoes = []\n",
    "    todas_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for entradas, labels in data_loader:\n",
    "            entradas, labels = entradas.to(device), labels.to(device)\n",
    "            saidas = modelo(entradas)\n",
    "            _, predicoes = torch.max(saidas, 1)\n",
    "\n",
    "            todas_predicoes.extend(predicoes.cpu().numpy())\n",
    "            todas_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Converter listas para arrays numpy\n",
    "    todas_predicoes = np.array(todas_predicoes)\n",
    "    todas_labels = np.array(todas_labels)\n",
    "\n",
    "    # Calcular acurácia\n",
    "    acuracia = accuracy_score(todas_labels, todas_predicoes)\n",
    "\n",
    "    # Calcular F1-score (média macro para considerar cada classe igualmente)\n",
    "    f1 = f1_score(todas_labels, todas_predicoes, average='macro')\n",
    "\n",
    "    # Calcular a matriz de confusão\n",
    "    matriz_confusao = confusion_matrix(todas_labels, todas_predicoes)\n",
    "\n",
    "    return acuracia, f1, matriz_confusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar a matriz de confusão\n",
    "def plotar_matriz_confusao(matriz_confusao, classes):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Época: 1/30\n",
      "Época 1/30, Treino: Erro: 1.1351, Acurácia: 56.73%, Validação: Erro: 0.9578, Acurácia: 63.41%, Tempo: 765.46s\n",
      "\n",
      "\n",
      "Época: 2/30\n",
      "Época 2/30, Treino: Erro: 0.9207, Acurácia: 65.92%, Validação: Erro: 0.8363, Acurácia: 69.22%, Tempo: 485.22s\n",
      "\n",
      "\n",
      "Época: 3/30\n",
      "Época 3/30, Treino: Erro: 0.8557, Acurácia: 68.12%, Validação: Erro: 0.8259, Acurácia: 69.43%, Tempo: 500.96s\n",
      "\n",
      "\n",
      "Época: 4/30\n",
      "Época 4/30, Treino: Erro: 0.8208, Acurácia: 69.60%, Validação: Erro: 0.7649, Acurácia: 71.15%, Tempo: 503.68s\n",
      "\n",
      "\n",
      "Época: 5/30\n",
      "Época 5/30, Treino: Erro: 0.7855, Acurácia: 70.94%, Validação: Erro: 0.8373, Acurácia: 69.36%, Tempo: 502.40s\n",
      "\n",
      "\n",
      "Época: 6/30\n"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/affectnet/processed/imagens_processed'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'affectnet.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/affectnet/processed/essenciais/'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'affectnetessenciais.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/affectnet/processed/landmarks/'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'affectnetlandmarks.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/affectnet/processed/landmarksConected/'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'affectnetlandmarksConected.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Época: 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Treinar e validar\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Certifique-se de que Trainer está definido ou importado corretamente\u001b[39;00m\n\u001b[0;32m     23\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n\u001b[1;32m---> 24\u001b[0m historico \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtreinar_e_validar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepocas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Avaliar o modelo após o treinamento\u001b[39;00m\n\u001b[0;32m     27\u001b[0m acuracia, f1, matriz_confusao \u001b[38;5;241m=\u001b[39m avaliar_modelo(modelo, data_loader_validacao, device)\n",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m, in \u001b[0;36mTrainer.treinar_e_validar\u001b[1;34m(self, epocas)\u001b[0m\n\u001b[0;32m     21\u001b[0m inicio_epoca \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mÉpoca: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoca\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepocas\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m erro_treino, acuracia_treino \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutar_fase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreino\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutar_fase(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidacao\u001b[39m\u001b[38;5;124m'\u001b[39m, return_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m fim_epoca \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[4], line 78\u001b[0m, in \u001b[0;36mTrainer.executar_fase\u001b[1;34m(self, fase, return_predictions)\u001b[0m\n\u001b[0;32m     75\u001b[0m     erro\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39motimizador\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 78\u001b[0m erro_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43merro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m entradas\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     79\u001b[0m _, predicoes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(saidas, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     80\u001b[0m acuracia_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicoes \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/Fer-2013/processed/imagens_processed/'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'fer.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "essenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/Fer-2013/processed/essenciais/'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'feressenciais.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/Fer-2013/processed/landmarks'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'ferlandmarks.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "dataset_path = '../data/Fer-2013/processed/landmarksFullConected'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Preparar DataLoaders\n",
    "# Certifique-se de que DataLoaderSetup está definido ou importado corretamente\n",
    "data_loader_setup = DataLoaderSetup(dataset_path, image_size=224, batch_size=32)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "modelo = CustomResNet50(num_classes).to(device)\n",
    "\n",
    "# Definir otimizador e critério de perda\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "nameModel = 'ferconected.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "# Certifique-se de que Trainer está definido ou importado corretamente\n",
    "trainer = Trainer(modelo, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "historico = trainer.treinar_e_validar(epocas=30)\n",
    "\n",
    "# Avaliar o modelo após o treinamento\n",
    "acuracia, f1, matriz_confusao = avaliar_modelo(modelo, data_loader_validacao, device)\n",
    "print(f\"Acurácia: {acuracia}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Matriz de Confusão:\\n{matriz_confusao}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
