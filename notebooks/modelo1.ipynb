{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResnetV1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResnetV1, self).__init__()\n",
    "        # Load the pre-trained ResNet-50 model\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze all layers\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze the last 4 parameters (typically layers close to the output)\n",
    "        for param in list(self.resnet.parameters())[-4:]:\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Modify the last fully connected layer to match the number of classes\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        data_loader_treino,\n",
    "        data_loader_validacao,\n",
    "        num_imagens_treino,\n",
    "        num_imagens_validacao,\n",
    "        device,\n",
    "        num_classes=8,\n",
    "        patience=5,\n",
    "        nameModel='nome do arquivo.pt',\n",
    "        otimizador=None,\n",
    "        scheduler=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inicializa o Trainer com opções para usar ou não otimizador, scheduler e patience.\n",
    "\n",
    "        Parâmetros:\n",
    "        - model: O modelo a ser treinado.\n",
    "        - data_loader_treino: DataLoader para o conjunto de treino.\n",
    "        - data_loader_validacao: DataLoader para o conjunto de validação.\n",
    "        - num_imagens_treino: Número total de imagens de treino.\n",
    "        - num_imagens_validacao: Número total de imagens de validação.\n",
    "        - device: Dispositivo onde o modelo será treinado (CPU ou GPU).\n",
    "        - num_classes: Número de classes de saída.\n",
    "        - patience: Número de épocas para o early stopping (opcional, pode ser None).\n",
    "        - nameModel: Nome do arquivo para salvar o melhor modelo.\n",
    "        - otimizador: O otimizador a ser usado (opcional, pode ser None).\n",
    "        - scheduler: O scheduler de learning rate a ser usado (opcional, pode ser None).\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data_loader_treino = data_loader_treino\n",
    "        self.data_loader_validacao = data_loader_validacao\n",
    "        self.num_imagens_treino = num_imagens_treino\n",
    "        self.num_imagens_validacao = num_imagens_validacao\n",
    "        self.device = device\n",
    "        self.funcao_erro = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Inicializa o otimizador apenas se for fornecido, senão cria um padrão\n",
    "        if otimizador is None:\n",
    "            self.otimizador = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "        else:\n",
    "            self.otimizador = otimizador\n",
    "        \n",
    "        # Inicializa o scheduler apenas se for fornecido\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        # Inicializa o patience\n",
    "        self.patience = patience\n",
    "\n",
    "        # Atualiza o caminho para salvar o modelo na pasta 'models/'\n",
    "        self.nameModel = nameModel\n",
    "        self.model_save_path = os.path.join('models', self.nameModel)\n",
    "        os.makedirs(os.path.dirname(self.model_save_path), exist_ok=True)\n",
    "\n",
    "    def treinar_e_validar(self, epocas):\n",
    "        historico = []\n",
    "        melhor_acuracia = 0.0\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        for epoca in range(epocas):\n",
    "            inicio_epoca = time.time()\n",
    "            print(f\"\\n\\nÉpoca: {epoca + 1}/{epocas}\")\n",
    "            erro_treino, acuracia_treino = self.executar_fase('treino')\n",
    "            erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao = self.executar_fase('validacao', return_predictions=True)\n",
    "\n",
    "            fim_epoca = time.time()\n",
    "            print(f\"Época {epoca + 1}/{epocas}, Treino: Erro: {erro_treino:.4f}, Acurácia: {acuracia_treino * 100:.2f}%, \"\n",
    "                  f\"Validação: Erro: {erro_validacao:.4f}, Acurácia: {acuracia_validacao * 100:.2f}%, Tempo: {fim_epoca - inicio_epoca:.2f}s\")\n",
    "\n",
    "            historico.append([erro_treino, erro_validacao, acuracia_treino, acuracia_validacao])\n",
    "            \n",
    "            # Atualiza o scheduler se ele estiver definido e o scheduler não for None\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(erro_validacao)\n",
    "\n",
    "            # Early stopping\n",
    "            if acuracia_validacao > melhor_acuracia:\n",
    "                melhor_acuracia = acuracia_validacao\n",
    "                print(f\"Validation accuracy improved to {melhor_acuracia:.4f}. Saving the model.\")\n",
    "                try:\n",
    "                    torch.save(self.model.state_dict(), self.model_save_path)\n",
    "                    print(f\"Modelo salvo com sucesso em {self.model_save_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao salvar o modelo: {e}\")\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "            if self.patience is not None and early_stop_counter >= self.patience:\n",
    "                print(\"Parando o treinamento devido ao early stopping.\")\n",
    "                break\n",
    "\n",
    "        # Calcular métricas finais\n",
    "        self.calcular_metricas(predicoes_validacao, labels_validacao)\n",
    "        return historico\n",
    "\n",
    "    def treinar_e_validar(self, epocas):\n",
    "        historico = []\n",
    "        melhor_acuracia = 0.0\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        for epoca in range(epocas):\n",
    "            inicio_epoca = time.time()\n",
    "            print(f\"\\n\\nÉpoca: {epoca + 1}/{epocas}\")\n",
    "            erro_treino, acuracia_treino = self.executar_fase('treino')\n",
    "            erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao = self.executar_fase('validacao', return_predictions=True)\n",
    "\n",
    "            fim_epoca = time.time()\n",
    "            print(f\"Época {epoca + 1}/{epocas}, Treino: Erro: {erro_treino:.4f}, Acurácia: {acuracia_treino * 100:.2f}%, \"\n",
    "                  f\"Validação: Erro: {erro_validacao:.4f}, Acurácia: {acuracia_validacao * 100:.2f}%, Tempo: {fim_epoca - inicio_epoca:.2f}s\")\n",
    "\n",
    "            historico.append([erro_treino, erro_validacao, acuracia_treino, acuracia_validacao])\n",
    "            \n",
    "            # Atualiza o scheduler se ele estiver definido\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(erro_validacao)\n",
    "\n",
    "            # Early stopping\n",
    "            if acuracia_validacao > melhor_acuracia:\n",
    "                melhor_acuracia = acuracia_validacao\n",
    "                print(f\"Validation accuracy improved to {melhor_acuracia:.4f}. Saving the model.\")\n",
    "                try:\n",
    "                    torch.save(self.model.state_dict(), self.model_save_path)\n",
    "                    print(f\"Modelo salvo com sucesso em {self.model_save_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao salvar o modelo: {e}\")\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "            if self.patience is not None and early_stop_counter >= self.patience:\n",
    "                print(\"Parando o treinamento devido ao early stopping.\")\n",
    "                break\n",
    "\n",
    "        # Calcular métricas finais\n",
    "        self.calcular_metricas(predicoes_validacao, labels_validacao)\n",
    "        return historico\n",
    "\n",
    "    def executar_fase(self, fase, return_predictions=False):\n",
    "        if fase == 'treino':\n",
    "            self.model.train()\n",
    "            data_loader = self.data_loader_treino\n",
    "            num_imagens = self.num_imagens_treino\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            data_loader = self.data_loader_validacao\n",
    "            num_imagens = self.num_imagens_validacao\n",
    "\n",
    "        erro_total = 0.0\n",
    "        acuracia_total = 0.0\n",
    "        todas_predicoes = []\n",
    "        todas_labels = []\n",
    "\n",
    "        with torch.set_grad_enabled(fase == 'treino'):\n",
    "            print(f\"\\nExecutando a fase de {fase}...\")\n",
    "            for entradas, labels in data_loader:\n",
    "                entradas, labels = entradas.to(self.device), labels.to(self.device)\n",
    "\n",
    "                if fase == 'treino':\n",
    "                    self.otimizador.zero_grad()\n",
    "\n",
    "                saidas = self.model(entradas)\n",
    "                erro = self.funcao_erro(saidas, labels)\n",
    "\n",
    "                if fase == 'treino':\n",
    "                    erro.backward()\n",
    "                    self.otimizador.step()\n",
    "                erro_total += erro.item() * entradas.size(0)\n",
    "                _, predicoes = torch.max(saidas, 1)\n",
    "                acuracia_total += (predicoes == labels).sum().item()\n",
    "\n",
    "                if return_predictions:\n",
    "                    todas_predicoes.extend(predicoes.cpu().numpy())\n",
    "                    todas_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "\n",
    "        erro_medio = erro_total / num_imagens\n",
    "        acuracia_media = acuracia_total / num_imagens\n",
    "\n",
    "        if return_predictions:\n",
    "            return erro_medio, acuracia_media, todas_predicoes, todas_labels\n",
    "        else:\n",
    "            return erro_medio, acuracia_media\n",
    "\n",
    "    def calcular_metricas(self, predicoes, labels):\n",
    "        acuracia = accuracy_score(labels, predicoes)\n",
    "        precisao = precision_score(labels, predicoes, average='weighted', zero_division=0)\n",
    "        recall = recall_score(labels, predicoes, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(labels, predicoes, average='weighted', zero_division=0)\n",
    "\n",
    "        print(\"\\nMétricas de Validação:\")\n",
    "        print(f\"Acurácia: {acuracia:.4f}\")\n",
    "        print(f\"Precisão: {precisao:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "        print(\"\\nRelatório de Classificação:\")\n",
    "        print(classification_report(labels, predicoes, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "class DataLoaderSetup:\n",
    "    def __init__(self, dataset_path, image_size, batch_size, transformacoes=None):\n",
    "        \"\"\"\n",
    "        Inicializa a classe DataLoaderSetup.\n",
    "\n",
    "        Parâmetros:\n",
    "        - dataset_path: Caminho para o dataset.\n",
    "        - image_size: Tamanho da imagem para redimensionamento.\n",
    "        - batch_size: Tamanho do batch.\n",
    "        - transformacoes: Dicionário opcional com as transformações para 'treino' e 'validacao'. Se None, serão usadas transformações padrão.\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Se não forem fornecidas transformações, usa as transformações padrão\n",
    "        self.transformacoes = transformacoes or self.get_default_transforms()\n",
    "\n",
    "    def get_default_transforms(self):\n",
    "        \"\"\"\n",
    "        Define transformações padrão para o conjunto de treino e validação.\n",
    "        \"\"\"\n",
    "        transformacoes_de_imagens = {\n",
    "            'treino': transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.CenterCrop(self.image_size)\n",
    "            ]),\n",
    "            'validacao': transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.CenterCrop(self.image_size)\n",
    "            ])\n",
    "        }\n",
    "        return transformacoes_de_imagens\n",
    "\n",
    "    def get_data_loaders(self):\n",
    "        \"\"\"\n",
    "        Cria DataLoaders para os conjuntos de treino e validação, aplicando as transformações fornecidas ou padrão.\n",
    "        \"\"\"\n",
    "        # Usa as transformações fornecidas ou as padrão definidas no init\n",
    "        train_dataset = datasets.ImageFolder(os.path.join(self.dataset_path, 'treino'), transform=self.transformacoes['treino'])\n",
    "        val_dataset = datasets.ImageFolder(os.path.join(self.dataset_path, 'validacao'), transform=self.transformacoes['validacao'])\n",
    "\n",
    "        data_loader_treino = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        data_loader_validacao = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        num_imagens_treino = len(train_dataset)\n",
    "        num_imagens_validacao = len(val_dataset)\n",
    "        num_classes = len(train_dataset.classes)\n",
    "\n",
    "        return data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Época: 1/30\n",
      "\n",
      "Executando a fase de treino...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n\u001b[0;32m     42\u001b[0m epocas \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtreinar_e_validar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepocas\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 121\u001b[0m, in \u001b[0;36mTrainer.treinar_e_validar\u001b[1;34m(self, epocas)\u001b[0m\n\u001b[0;32m    119\u001b[0m inicio_epoca \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mÉpoca: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoca\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepocas\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m erro_treino, acuracia_treino \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutar_fase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreino\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutar_fase(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidacao\u001b[39m\u001b[38;5;124m'\u001b[39m, return_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    124\u001b[0m fim_epoca \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[6], line 184\u001b[0m, in \u001b[0;36mTrainer.executar_fase\u001b[1;34m(self, fase, return_predictions)\u001b[0m\n\u001b[0;32m    182\u001b[0m     erro\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39motimizador\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 184\u001b[0m erro_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43merro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m entradas\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    185\u001b[0m _, predicoes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(saidas, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    186\u001b[0m acuracia_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicoes \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# Caminho do dataset\n",
    "dataset_path = r'F:\\Git\\Teste\\FER\\affectnet\\affectnet2'\n",
    "\n",
    "# Definir dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Transformações personalizadas\n",
    "transformacoes_personalizadas = {\n",
    "    'treino': transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'validacao': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Preparar DataLoaders\n",
    "data_loader_setup = data_loader_setup = DataLoaderSetup(dataset_path,image_size=224,batch_size=32,transformacoes=transformacoes_personalizadas)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "model = ResnetV1(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "# model = CustomResNet50(num_classes).get_model().to(device)\n",
    "\n",
    "# Nome do modelo salvo e paciência para early stopping\n",
    "nameModel = 'affectnet.pt'\n",
    "patience = 5\n",
    "\n",
    "# Treinar e validar\n",
    "trainer = Trainer(model, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel)\n",
    "epocas = 30\n",
    "trainer.treinar_e_validar(epocas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# from torchvision import datasets, models, transforms\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# # Ensure the project root is in sys.path\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../')))\n",
    "\n",
    "# from src.data_processing.dataloader import DataLoaderSetup\n",
    "# from src.models.resnet_V1 import ResnetV1\n",
    "# from src.training.trainer import Trainer\n",
    "\n",
    "# # Number of classes\n",
    "# numero_de_classes = 8\n",
    "# model = ResnetV1(num_classes=numero_de_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# funcao_erro = nn.NLLLoss()\n",
    "# otimizador = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# # Dataset paths\n",
    "# dataset = r'F:\\Git\\Teste\\FER\\affectnet\\affectnet2'\n",
    "\n",
    "# nameModel = 'affectnet.pt'\n",
    "\n",
    "# # Custom transformations\n",
    "# transformacoes_personalizadas = {\n",
    "#     'treino': transforms.Compose([\n",
    "#         transforms.RandomRotation(15),\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.ToTensor()\n",
    "#     ]),\n",
    "#     'validacao': transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "# }\n",
    "\n",
    "# # Initialize DataLoaderSetup with custom transformations\n",
    "# data_loader_setup = DataLoaderSetup(\n",
    "#     dataset_path=dataset,\n",
    "#     image_size=224,\n",
    "#     batch_size=32,\n",
    "#     transformacoes=transformacoes_personalizadas\n",
    "# )\n",
    "\n",
    "# # Get data loaders\n",
    "# data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# # Verify data types\n",
    "# data_iter = iter(data_loader_treino)\n",
    "# images, labels = next(data_iter)\n",
    "# print(f\"Type of images: {type(images)}\")   # Should be <class 'torch.Tensor'>\n",
    "# print(f\"Type of labels: {type(labels)}\")   # Should be <class 'torch.Tensor'>\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# # Move the model to the device\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Optionally, verify that the model is on the correct device\n",
    "# for param in model.parameters():\n",
    "#     print(f\"Model parameter device: {param.device}\")\n",
    "#     break  # Check only the first parameter\n",
    "\n",
    "# # Train and validate\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     data_loader_treino=data_loader_treino,\n",
    "#     data_loader_validacao=data_loader_validacao,\n",
    "#     num_imagens_treino=num_imagens_treino,\n",
    "#     num_imagens_validacao=num_imagens_validacao,\n",
    "#     device=device,\n",
    "#     num_classes=num_classes,\n",
    "#     name_model=nameModel,\n",
    "#     otimizador=otimizador,\n",
    "#     funcao_erro=funcao_erro\n",
    "# )\n",
    "\n",
    "# epocas = 30\n",
    "# trainer.treinar_e_validar(epocas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
