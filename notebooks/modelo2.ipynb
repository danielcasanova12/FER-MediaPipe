{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomResNet50:\n",
    "    def __init__(self, num_classes):\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        data_loader_treino,\n",
    "        data_loader_validacao,\n",
    "        num_imagens_treino,\n",
    "        num_imagens_validacao,\n",
    "        device,\n",
    "        num_classes=8,\n",
    "        patience=5,\n",
    "        nameModel='nome do arquivo.pt',\n",
    "        otimizador=None,\n",
    "        scheduler=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inicializa o Trainer com opções para usar ou não otimizador, scheduler e patience.\n",
    "\n",
    "        Parâmetros:\n",
    "        - model: O modelo a ser treinado.\n",
    "        - data_loader_treino: DataLoader para o conjunto de treino.\n",
    "        - data_loader_validacao: DataLoader para o conjunto de validação.\n",
    "        - num_imagens_treino: Número total de imagens de treino.\n",
    "        - num_imagens_validacao: Número total de imagens de validação.\n",
    "        - device: Dispositivo onde o modelo será treinado (CPU ou GPU).\n",
    "        - num_classes: Número de classes de saída.\n",
    "        - patience: Número de épocas para o early stopping (opcional, pode ser None).\n",
    "        - nameModel: Nome do arquivo para salvar o melhor modelo.\n",
    "        - otimizador: O otimizador a ser usado (opcional, pode ser None).\n",
    "        - scheduler: O scheduler de learning rate a ser usado (opcional, pode ser None).\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data_loader_treino = data_loader_treino\n",
    "        self.data_loader_validacao = data_loader_validacao\n",
    "        self.num_imagens_treino = num_imagens_treino\n",
    "        self.num_imagens_validacao = num_imagens_validacao\n",
    "        self.device = device\n",
    "        self.funcao_erro = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Inicializa o otimizador apenas se for fornecido, senão cria um padrão\n",
    "        if otimizador is None:\n",
    "            self.otimizador = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "        else:\n",
    "            self.otimizador = otimizador\n",
    "        \n",
    "        # Inicializa o scheduler apenas se for fornecido\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        # Inicializa o patience\n",
    "        self.patience = patience\n",
    "\n",
    "        # Atualiza o caminho para salvar o modelo na pasta 'models/'\n",
    "        self.nameModel = nameModel\n",
    "        self.model_save_path = os.path.join('models', self.nameModel)\n",
    "        os.makedirs(os.path.dirname(self.model_save_path), exist_ok=True)\n",
    "\n",
    "    def treinar_e_validar(self, epocas):\n",
    "        historico = []\n",
    "        melhor_acuracia = 0.0\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        for epoca in range(epocas):\n",
    "            inicio_epoca = time.time()\n",
    "            print(f\"\\n\\nÉpoca: {epoca + 1}/{epocas}\")\n",
    "            erro_treino, acuracia_treino = self.executar_fase('treino')\n",
    "            erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao = self.executar_fase('validacao', return_predictions=True)\n",
    "\n",
    "            fim_epoca = time.time()\n",
    "            print(f\"Época {epoca + 1}/{epocas}, Treino: Erro: {erro_treino:.4f}, Acurácia: {acuracia_treino * 100:.2f}%, \"\n",
    "                  f\"Validação: Erro: {erro_validacao:.4f}, Acurácia: {acuracia_validacao * 100:.2f}%, Tempo: {fim_epoca - inicio_epoca:.2f}s\")\n",
    "\n",
    "            historico.append([erro_treino, erro_validacao, acuracia_treino, acuracia_validacao])\n",
    "            \n",
    "            # Atualiza o scheduler se ele estiver definido e o scheduler não for None\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(erro_validacao)\n",
    "\n",
    "            # Early stopping\n",
    "            if acuracia_validacao > melhor_acuracia:\n",
    "                melhor_acuracia = acuracia_validacao\n",
    "                print(f\"Validation accuracy improved to {melhor_acuracia:.4f}. Saving the model.\")\n",
    "                try:\n",
    "                    torch.save(self.model.state_dict(), self.model_save_path)\n",
    "                    print(f\"Modelo salvo com sucesso em {self.model_save_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao salvar o modelo: {e}\")\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "            if self.patience is not None and early_stop_counter >= self.patience:\n",
    "                print(\"Parando o treinamento devido ao early stopping.\")\n",
    "                break\n",
    "\n",
    "        # Calcular métricas finais\n",
    "        self.calcular_metricas(predicoes_validacao, labels_validacao)\n",
    "        return historico\n",
    "\n",
    "    def treinar_e_validar(self, epocas):\n",
    "        historico = []\n",
    "        melhor_acuracia = 0.0\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        for epoca in range(epocas):\n",
    "            inicio_epoca = time.time()\n",
    "            print(f\"\\n\\nÉpoca: {epoca + 1}/{epocas}\")\n",
    "            erro_treino, acuracia_treino = self.executar_fase('treino')\n",
    "            erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao = self.executar_fase('validacao', return_predictions=True)\n",
    "\n",
    "            fim_epoca = time.time()\n",
    "            print(f\"Época {epoca + 1}/{epocas}, Treino: Erro: {erro_treino:.4f}, Acurácia: {acuracia_treino * 100:.2f}%, \"\n",
    "                  f\"Validação: Erro: {erro_validacao:.4f}, Acurácia: {acuracia_validacao * 100:.2f}%, Tempo: {fim_epoca - inicio_epoca:.2f}s\")\n",
    "\n",
    "            historico.append([erro_treino, erro_validacao, acuracia_treino, acuracia_validacao])\n",
    "            \n",
    "            # Atualiza o scheduler se ele estiver definido\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(erro_validacao)\n",
    "\n",
    "            # Early stopping\n",
    "            if acuracia_validacao > melhor_acuracia:\n",
    "                melhor_acuracia = acuracia_validacao\n",
    "                print(f\"Validation accuracy improved to {melhor_acuracia:.4f}. Saving the model.\")\n",
    "                try:\n",
    "                    torch.save(self.model.state_dict(), self.model_save_path)\n",
    "                    print(f\"Modelo salvo com sucesso em {self.model_save_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao salvar o modelo: {e}\")\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "            if self.patience is not None and early_stop_counter >= self.patience:\n",
    "                print(\"Parando o treinamento devido ao early stopping.\")\n",
    "                break\n",
    "\n",
    "        # Calcular métricas finais\n",
    "        self.calcular_metricas(predicoes_validacao, labels_validacao)\n",
    "        return historico\n",
    "\n",
    "    def executar_fase(self, fase, return_predictions=False):\n",
    "        if fase == 'treino':\n",
    "            self.model.train()\n",
    "            data_loader = self.data_loader_treino\n",
    "            num_imagens = self.num_imagens_treino\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            data_loader = self.data_loader_validacao\n",
    "            num_imagens = self.num_imagens_validacao\n",
    "\n",
    "        erro_total = 0.0\n",
    "        acuracia_total = 0.0\n",
    "        todas_predicoes = []\n",
    "        todas_labels = []\n",
    "\n",
    "        with torch.set_grad_enabled(fase == 'treino'):\n",
    "            print(f\"\\nExecutando a fase de {fase}...\")\n",
    "            for entradas, labels in data_loader:\n",
    "                entradas, labels = entradas.to(self.device), labels.to(self.device)\n",
    "\n",
    "                if fase == 'treino':\n",
    "                    self.otimizador.zero_grad()\n",
    "\n",
    "                saidas = self.model(entradas)\n",
    "                erro = self.funcao_erro(saidas, labels)\n",
    "\n",
    "                if fase == 'treino':\n",
    "                    erro.backward()\n",
    "                    self.otimizador.step()\n",
    "                erro_total += erro.item() * entradas.size(0)\n",
    "                _, predicoes = torch.max(saidas, 1)\n",
    "                acuracia_total += (predicoes == labels).sum().item()\n",
    "\n",
    "                if return_predictions:\n",
    "                    todas_predicoes.extend(predicoes.cpu().numpy())\n",
    "                    todas_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "\n",
    "        erro_medio = erro_total / num_imagens\n",
    "        acuracia_media = acuracia_total / num_imagens\n",
    "\n",
    "        if return_predictions:\n",
    "            return erro_medio, acuracia_media, todas_predicoes, todas_labels\n",
    "        else:\n",
    "            return erro_medio, acuracia_media\n",
    "\n",
    "    def calcular_metricas(self, predicoes, labels):\n",
    "        acuracia = accuracy_score(labels, predicoes)\n",
    "        precisao = precision_score(labels, predicoes, average='weighted', zero_division=0)\n",
    "        recall = recall_score(labels, predicoes, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(labels, predicoes, average='weighted', zero_division=0)\n",
    "\n",
    "        print(\"\\nMétricas de Validação:\")\n",
    "        print(f\"Acurácia: {acuracia:.4f}\")\n",
    "        print(f\"Precisão: {precisao:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "        print(\"\\nRelatório de Classificação:\")\n",
    "        print(classification_report(labels, predicoes, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "class DataLoaderSetup:\n",
    "    def __init__(self, dataset_path, image_size, batch_size, transformacoes=None):\n",
    "        \"\"\"\n",
    "        Inicializa a classe DataLoaderSetup.\n",
    "\n",
    "        Parâmetros:\n",
    "        - dataset_path: Caminho para o dataset.\n",
    "        - image_size: Tamanho da imagem para redimensionamento.\n",
    "        - batch_size: Tamanho do batch.\n",
    "        - transformacoes: Dicionário opcional com as transformações para 'treino' e 'validacao'. Se None, serão usadas transformações padrão.\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Se não forem fornecidas transformações, usa as transformações padrão\n",
    "        self.transformacoes = transformacoes or self.get_default_transforms()\n",
    "\n",
    "    def get_default_transforms(self):\n",
    "        \"\"\"\n",
    "        Define transformações padrão para o conjunto de treino e validação.\n",
    "        \"\"\"\n",
    "        transformacoes_de_imagens = {\n",
    "            'treino': transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.CenterCrop(self.image_size)\n",
    "            ]),\n",
    "            'validacao': transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.CenterCrop(self.image_size)\n",
    "            ])\n",
    "        }\n",
    "        return transformacoes_de_imagens\n",
    "\n",
    "    def get_data_loaders(self):\n",
    "        \"\"\"\n",
    "        Cria DataLoaders para os conjuntos de treino e validação, aplicando as transformações fornecidas ou padrão.\n",
    "        \"\"\"\n",
    "        # Usa as transformações fornecidas ou as padrão definidas no init\n",
    "        train_dataset = datasets.ImageFolder(os.path.join(self.dataset_path, 'treino'), transform=self.transformacoes['treino'])\n",
    "        val_dataset = datasets.ImageFolder(os.path.join(self.dataset_path, 'validacao'), transform=self.transformacoes['validacao'])\n",
    "\n",
    "        data_loader_treino = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        data_loader_validacao = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        num_imagens_treino = len(train_dataset)\n",
    "        num_imagens_validacao = len(val_dataset)\n",
    "        num_classes = len(train_dataset.classes)\n",
    "\n",
    "        return data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo utilizado: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Época: 1/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 1/30, Treino: Erro: 1.6289, Acurácia: 27.78%, Validação: Erro: 1.5275, Acurácia: 28.37%, Tempo: 827.38s\n",
      "Validation accuracy improved to 0.2837. Saving the model.\n",
      "Modelo salvo com sucesso em models\\affectnettestee.pt\n",
      "\n",
      "\n",
      "Época: 2/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 2/30, Treino: Erro: 1.5710, Acurácia: 28.08%, Validação: Erro: 1.5213, Acurácia: 28.13%, Tempo: 349.44s\n",
      "\n",
      "\n",
      "Época: 3/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 3/30, Treino: Erro: 1.5552, Acurácia: 28.03%, Validação: Erro: 1.5531, Acurácia: 28.68%, Tempo: 373.53s\n",
      "Validation accuracy improved to 0.2868. Saving the model.\n",
      "Modelo salvo com sucesso em models\\affectnettestee.pt\n",
      "\n",
      "\n",
      "Época: 4/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 4/30, Treino: Erro: 1.5528, Acurácia: 28.39%, Validação: Erro: 1.5237, Acurácia: 28.51%, Tempo: 381.76s\n",
      "\n",
      "\n",
      "Época: 5/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 5/30, Treino: Erro: 1.5468, Acurácia: 28.13%, Validação: Erro: 1.5211, Acurácia: 29.23%, Tempo: 373.74s\n",
      "Validation accuracy improved to 0.2923. Saving the model.\n",
      "Modelo salvo com sucesso em models\\affectnettestee.pt\n",
      "\n",
      "\n",
      "Época: 6/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 6/30, Treino: Erro: 1.5424, Acurácia: 28.87%, Validação: Erro: 1.5689, Acurácia: 26.62%, Tempo: 383.97s\n",
      "\n",
      "\n",
      "Época: 7/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 7/30, Treino: Erro: 1.5302, Acurácia: 30.34%, Validação: Erro: 1.5780, Acurácia: 30.85%, Tempo: 399.18s\n",
      "Validation accuracy improved to 0.3085. Saving the model.\n",
      "Modelo salvo com sucesso em models\\affectnettestee.pt\n",
      "\n",
      "\n",
      "Época: 8/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 8/30, Treino: Erro: 1.5198, Acurácia: 30.89%, Validação: Erro: 1.4994, Acurácia: 29.81%, Tempo: 345.08s\n",
      "\n",
      "\n",
      "Época: 9/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 9/30, Treino: Erro: 1.5017, Acurácia: 32.00%, Validação: Erro: 1.4522, Acurácia: 33.49%, Tempo: 372.67s\n",
      "Validation accuracy improved to 0.3349. Saving the model.\n",
      "Modelo salvo com sucesso em models\\affectnettestee.pt\n",
      "\n",
      "\n",
      "Época: 10/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 10/30, Treino: Erro: 1.4941, Acurácia: 32.35%, Validação: Erro: 1.8165, Acurácia: 26.96%, Tempo: 380.03s\n",
      "\n",
      "\n",
      "Época: 11/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 11/30, Treino: Erro: 1.4837, Acurácia: 32.33%, Validação: Erro: 1.4023, Acurácia: 35.90%, Tempo: 379.67s\n",
      "Validation accuracy improved to 0.3590. Saving the model.\n",
      "Modelo salvo com sucesso em models\\affectnettestee.pt\n",
      "\n",
      "\n",
      "Época: 12/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 12/30, Treino: Erro: 1.4681, Acurácia: 33.58%, Validação: Erro: 1.4540, Acurácia: 32.87%, Tempo: 389.62s\n",
      "\n",
      "\n",
      "Época: 13/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 13/30, Treino: Erro: 1.4602, Acurácia: 33.62%, Validação: Erro: 1.4005, Acurácia: 35.87%, Tempo: 391.04s\n",
      "\n",
      "\n",
      "Época: 14/30\n",
      "\n",
      "Executando a fase de treino...\n",
      "\n",
      "Executando a fase de validacao...\n",
      "Época 14/30, Treino: Erro: 1.4555, Acurácia: 33.52%, Validação: Erro: 1.6155, Acurácia: 30.85%, Tempo: 380.02s\n",
      "\n",
      "\n",
      "Época: 15/30\n",
      "\n",
      "Executando a fase de treino...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel,optimizer)\n\u001b[0;32m     46\u001b[0m epocas \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m---> 47\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtreinar_e_validar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepocas\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 121\u001b[0m, in \u001b[0;36mTrainer.treinar_e_validar\u001b[1;34m(self, epocas)\u001b[0m\n\u001b[0;32m    119\u001b[0m inicio_epoca \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mÉpoca: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoca\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepocas\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m erro_treino, acuracia_treino \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutar_fase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreino\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m erro_validacao, acuracia_validacao, predicoes_validacao, labels_validacao \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutar_fase(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidacao\u001b[39m\u001b[38;5;124m'\u001b[39m, return_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    124\u001b[0m fim_epoca \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[2], line 184\u001b[0m, in \u001b[0;36mTrainer.executar_fase\u001b[1;34m(self, fase, return_predictions)\u001b[0m\n\u001b[0;32m    182\u001b[0m     erro\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39motimizador\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 184\u001b[0m erro_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43merro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m entradas\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    185\u001b[0m _, predicoes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(saidas, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    186\u001b[0m acuracia_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicoes \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from torchvision import transforms\n",
    "# Adicionar o caminho raiz do projeto ao sys.path\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Caminho do dataset\n",
    "dataset_path = r'F:\\Git\\Teste\\FER\\affectnet\\affectnet2'\n",
    "\n",
    "# Definir dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo utilizado: {device}\")\n",
    "\n",
    "# Transformações personalizadas\n",
    "transformacoes_personalizadas = {\n",
    "    'treino': transforms.Compose([\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validacao': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "# Preparar DataLoaders\n",
    "data_loader_setup = data_loader_setup = DataLoaderSetup(dataset_path,image_size=224,batch_size=32,transformacoes=transformacoes_personalizadas)\n",
    "data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, num_classes = data_loader_setup.get_data_loaders()\n",
    "\n",
    "# Carregar o modelo\n",
    "model = CustomResNet50(num_classes).get_model().to(device)\n",
    "\n",
    "# Nome do modelo salvo e paciência para early stopping\n",
    "nameModel = 'affectnettestee.pt'\n",
    "patience = 8\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "# Treinar e validar\n",
    "trainer = Trainer(model, data_loader_treino, data_loader_validacao, num_imagens_treino, num_imagens_validacao, device, num_classes, patience, nameModel,optimizer)\n",
    "epocas = 30\n",
    "trainer.treinar_e_validar(epocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
